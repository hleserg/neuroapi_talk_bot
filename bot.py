import asyncio
import logging
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command, CommandObject
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from aiogram.fsm.storage.memory import MemoryStorage
from neuroapi import neuroapi_client
from config import BOT_TOKEN, MODELS, DEFAULT_MODEL, YANDEX_VOICES
import io

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–æ—Ç –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä
bot = Bot(token=BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
class ImageGenerationStates(StatesGroup):
    waiting_for_prompt = State()

def create_model_keyboard() -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –º–æ–¥–µ–ª–µ–π"""
    keyboard = []
    for model_id, model_info in MODELS.items():
        button = InlineKeyboardButton(
            text=f"{model_info['name']}",
            callback_data=f"model_{model_id}"
        )
        keyboard.append([button])
    return InlineKeyboardMarkup(inline_keyboard=keyboard)

def create_voice_keyboard() -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –≥–æ–ª–æ—Å–æ–≤"""
    keyboard = []
    for voice_id, voice_info in YANDEX_VOICES.items():
        button = InlineKeyboardButton(
            text=f"{voice_info['name']}",
            callback_data=f"voice_{voice_id}"
        )
        keyboard.append([button])
    return InlineKeyboardMarkup(inline_keyboard=keyboard)

@dp.message(Command("start"))
async def cmd_start(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user_name = message.from_user.first_name or "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
    welcome_text = f"""
–ü—Ä–∏–≤–µ—Ç, {user_name}! üëã

–Ø –±–æ—Ç-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –ò–ò. –Ø –º–æ–≥—É:
‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã
‚Ä¢ –í–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚Ä¢ –ü–æ–º–æ–≥–∞—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
‚Ä¢ –û–±—â–∞—Ç—å—Å—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
‚Ä¢ –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/start - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –±–µ—Å–µ–¥—ã
/help - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
/models - —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
/model - –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å
/current - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
/generate_image - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {MODELS[DEFAULT_MODEL]["name"]}
"""
    await message.answer(welcome_text)

@dp.message(Command("models"))
async def cmd_models(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    user_id = message.from_user.id
    current_model = neuroapi_client._get_user_model(user_id)
    
    models_text = "<b>üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:</b>\n\n"
    for model_id, model_info in MODELS.items():
        current_mark = "‚úÖ " if model_id == current_model else ""
        models_text += f"{current_mark}<b>{model_info['name']}</b> (<code>{model_id}</code>)\n"
        models_text += f"‚îî {model_info['description']}\n\n"
    
    models_text += "\n–î–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É:\n<code>/model [id_–º–æ–¥–µ–ª–∏]</code>"
    
    await message.answer(models_text, parse_mode="HTML")

@dp.message(Command("model"))
async def cmd_model(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
    keyboard = create_model_keyboard()
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—â–µ–Ω–∏—è:",
        reply_markup=keyboard
    )

@dp.callback_query(lambda c: c.data.startswith('model_'))
async def process_model_selection(callback_query: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º ID –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ callback_data
        model_id = callback_query.data.replace('model_', '')
        user_id = callback_query.from_user.id
        
        if model_id not in MODELS:
            await callback_query.answer("‚ùå –û—à–∏–±–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        neuroapi_client.set_user_model(user_id, model_id)
        model_name = MODELS[model_id]["name"]
        
        # –û—Ç–≤–µ—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await callback_query.message.edit_text(
            f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {model_name}.\n"
            "–ö–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω."
        )
        await callback_query.answer()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–æ–¥–µ–ª–∏: {e}")
        await callback_query.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–æ–¥–µ–ª–∏")

@dp.message(Command("clear"))
async def cmd_clear(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /clear - –æ—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã"""
    user_id = message.from_user.id
    neuroapi_client.clear_context(user_id)
    await message.answer("‚úÖ –ò—Å—Ç–æ—Ä–∏—è –±–µ—Å–µ–¥—ã –æ—á–∏—â–µ–Ω–∞. –ú–æ–∂–µ–º –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ!")

@dp.message(Command("help"))
async def cmd_help(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
    user_id = message.from_user.id
    current_model = neuroapi_client._get_user_model(user_id)
    current_model_name = MODELS[current_model]["name"]
    voice_enabled = neuroapi_client.is_voice_mode_enabled(user_id)
    current_voice = neuroapi_client.get_user_voice(user_id)
    voice_name = YANDEX_VOICES[current_voice]["name"]
    
    help_text = f"""
üìö –°–ø—Ä–∞–≤–∫–∞ –ø–æ –±–æ—Ç—É

–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model_name}
–ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º: {'üîä –í–∫–ª—é—á–µ–Ω' if voice_enabled else 'üîá –í—ã–∫–ª—é—á–µ–Ω'}
–¢–µ–∫—É—â–∏–π –≥–æ–ª–æ—Å: {voice_name}

–Ø —É–º–µ—é:
‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ª—é–±—ã–º —Ç–µ–º–∞–º
‚Ä¢ –ü–æ–º–æ–≥–∞—Ç—å —Å —É—á–µ–±–æ–π –∏ —Ä–∞–±–æ—Ç–æ–π  
‚Ä¢ –ü–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –∏ –∫–æ–¥
‚Ä¢ –ü–µ—Ä–µ–≤–æ–¥–∏—Ç—å —Ç–µ–∫—Å—Ç—ã
‚Ä¢ –û–±—ä—è—Å–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
‚Ä¢ –í–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥ —Å –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
‚Ä¢ –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é

–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/start - –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
/help - —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞
/models - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
/model - –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å
/current - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
/generate_image - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

–ì–æ–ª–æ—Å–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/voice_mode_on - –≤–∫–ª—é—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
/voice_mode_off - –≤—ã–∫–ª—é—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
/voice - –≤—ã–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å
/voices - —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≥–æ–ª–æ—Å–æ–≤
/voice_status - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞

–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –º–Ω–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –æ—Ç–≤–µ—á—É!
"""
    await message.answer(help_text)

@dp.message(Command("current"))
async def cmd_current(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    user_id = message.from_user.id
    current_model = neuroapi_client._get_user_model(user_id)
    model_info = MODELS[current_model]
    
    current_text = f"""
<b>–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å:</b>

‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ: <b>{model_info['name']}</b>
‚Ä¢ ID: <code>{current_model}</code>
‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {model_info['description']}
‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {model_info['max_tokens']} —Ç–æ–∫–µ–Ω–æ–≤
‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {model_info['temperature']}

–î–ª—è —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /model
"""
    await message.answer(current_text, parse_mode="HTML")

@dp.message(Command("voice"))
async def cmd_voice(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞"""
    keyboard = create_voice_keyboard()
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏:",
        reply_markup=keyboard
    )

@dp.message(Command("voices"))
async def cmd_voices(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤"""
    user_id = message.from_user.id
    current_voice = neuroapi_client.get_user_voice(user_id)
    
    voices_text = "<b>üé§ –î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞:</b>\n\n"
    for voice_id, voice_info in YANDEX_VOICES.items():
        current_mark = "‚úÖ " if voice_id == current_voice else ""
        voices_text += f"{current_mark}<b>{voice_info['name']}</b> (<code>{voice_id}</code>)\n"
        voices_text += f"‚îî {voice_info['description']}\n\n"
    
    voices_text += "\n–î–ª—è –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /voice"
    
    await message.answer(voices_text, parse_mode="HTML")

@dp.message(Command("voice_mode_on"))
@dp.message(Command("–≤–∫–ª—é—á–∏—Ç—å_–≥–æ–ª–æ—Å–æ–≤–æ–π_—Ä–µ–∂–∏–º"))
async def cmd_enable_voice_mode(message: Message):
    """–í–∫–ª—é—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º"""
    user_id = message.from_user.id
    neuroapi_client.set_voice_mode(user_id, True)
    
    current_voice = neuroapi_client.get_user_voice(user_id)
    voice_name = YANDEX_VOICES[current_voice]["name"]
    
    await message.answer(
        f"üîä –ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º –≤–∫–ª—é—á–µ–Ω!\n\n"
        f"–¢–µ–∫—É—â–∏–π –≥–æ–ª–æ—Å: {voice_name}\n"
        f"–¢–µ–ø–µ—Ä—å —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.\n\n"
        f"–î–ª—è —Å–º–µ–Ω—ã –≥–æ–ª–æ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /voice\n"
        f"–î–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /voice_mode_off"
    )

@dp.message(Command("voice_mode_off"))
@dp.message(Command("–≤—ã–∫–ª—é—á–∏—Ç—å_–≥–æ–ª–æ—Å–æ–≤–æ–π_—Ä–µ–∂–∏–º"))
async def cmd_disable_voice_mode(message: Message):
    """–í—ã–∫–ª—é—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º"""
    user_id = message.from_user.id
    neuroapi_client.set_voice_mode(user_id, False)
    
    await message.answer(
        "üîá –ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º –≤—ã–∫–ª—é—á–µ–Ω.\n"
        "–¢–µ–ø–µ—Ä—å —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏."
    )

@dp.message(Command("voice_status"))
@dp.message(Command("—Å—Ç–∞—Ç—É—Å_–≥–æ–ª–æ—Å–∞"))
async def cmd_voice_status(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
    user_id = message.from_user.id
    voice_enabled = neuroapi_client.is_voice_mode_enabled(user_id)
    current_voice = neuroapi_client.get_user_voice(user_id)
    voice_info = YANDEX_VOICES[current_voice]
    
    status_text = f"""
<b>üé§ –°—Ç–∞—Ç—É—Å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞:</b>

‚Ä¢ –†–µ–∂–∏–º: {'üîä –í–∫–ª—é—á–µ–Ω' if voice_enabled else 'üîá –í—ã–∫–ª—é—á–µ–Ω'}
‚Ä¢ –¢–µ–∫—É—â–∏–π –≥–æ–ª–æ—Å: <b>{voice_info['name']}</b>
‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {voice_info['description']}

–ö–æ–º–∞–Ω–¥—ã:
/voice_mode_on –∏–ª–∏ /–≤–∫–ª—é—á–∏—Ç—å_–≥–æ–ª–æ—Å–æ–≤–æ–π_—Ä–µ–∂–∏–º - –≤–∫–ª—é—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
/voice_mode_off –∏–ª–∏ /–≤—ã–∫–ª—é—á–∏—Ç—å_–≥–æ–ª–æ—Å–æ–≤–æ–π_—Ä–µ–∂–∏–º - –≤—ã–∫–ª—é—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã
/voice - –≤—ã–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å
/voices - —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≥–æ–ª–æ—Å–æ–≤
"""
    await message.answer(status_text, parse_mode="HTML")

@dp.message(Command("generate_image"))
async def cmd_generate_image(message: Message, state: FSMContext):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    await message.answer("üé® –û–ø–∏—à–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
    await state.set_state(ImageGenerationStates.waiting_for_prompt)

@dp.message(ImageGenerationStates.waiting_for_prompt)
async def process_image_prompt(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    user_id = message.from_user.id
    prompt = message.text
    
    if not prompt:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    processing_message = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
    
    try:
        await bot.send_chat_action(chat_id=message.chat.id, action="upload_photo")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = await neuroapi_client.generate_image(prompt)
        
        if image_data:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            from aiogram.types import BufferedInputFile
            
            image_file = BufferedInputFile(
                file=image_data,
                filename="generated_image.png"
            )
            
            await processing_message.delete()
            await bot.send_photo(
                chat_id=message.chat.id,
                photo=image_file,
                caption=f"üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É:\n<i>{prompt}</i>",
                parse_mode="HTML"
            )
        else:
            await processing_message.edit_text(
                "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ."
            )
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        await processing_message.edit_text(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        )
    
    finally:
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        await state.clear()

@dp.callback_query(lambda c: c.data.startswith('voice_'))
async def process_voice_selection(callback_query: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º ID –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞ –∏–∑ callback_data
        voice_id = callback_query.data.replace('voice_', '')
        user_id = callback_query.from_user.id
        
        if voice_id not in YANDEX_VOICES:
            await callback_query.answer("‚ùå –û—à–∏–±–∫–∞: –≥–æ–ª–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å
        neuroapi_client.set_user_voice(user_id, voice_id)
        voice_name = YANDEX_VOICES[voice_id]["name"]
        
        # –û—Ç–≤–µ—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await callback_query.message.edit_text(
            f"‚úÖ –ì–æ–ª–æ—Å —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ {voice_name}.\n"
            f"–û–ø–∏—Å–∞–Ω–∏–µ: {YANDEX_VOICES[voice_id]['description']}"
        )
        await callback_query.answer()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –≥–æ–ª–æ—Å–∞: {e}")
        await callback_query.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –≥–æ–ª–æ—Å–∞")

@dp.message(F.voice)
async def handle_voice_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = message.from_user.id
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ –∞—É–¥–∏–æ –ø–æ–ª—É—á–µ–Ω–æ
    processing_message = await message.answer("üé§ –ê—É–¥–∏–æ –ø–æ–ª—É—á–µ–Ω–æ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...")
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
        voice_file = await bot.get_file(message.voice.file_id)
        voice_io = await bot.download_file(voice_file.file_path)
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
        transcribed_text = await neuroapi_client.transcribe_audio(voice_io.read())
        
        if transcribed_text.startswith("–û—à–∏–±–∫–∞:"):
            await processing_message.edit_text(transcribed_text)
            return
            
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        await processing_message.edit_text(f"<i>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:</i>\n{transcribed_text}", parse_mode="HTML")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º "–ø–µ—á–∞—Ç–∞–µ—Ç..."
        typing_message = await message.answer("...")
        await bot.send_chat_action(chat_id=message.chat.id, action="typing")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = await neuroapi_client.generate_response(user_id, transcribed_text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º
        if neuroapi_client.is_voice_mode_enabled(user_id):
            # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–æ—á–∫–∞–º–∏
            await typing_message.delete()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
            voice_message = await message.answer("üé§ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ–ª–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_voice = neuroapi_client.get_user_voice(user_id)
            
            # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
            audio_data = await neuroapi_client.synthesize_speech(response, user_voice)
            
            if audio_data:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                from aiogram.types import BufferedInputFile
                
                audio_file = BufferedInputFile(
                    file=audio_data,
                    filename="voice_response.ogg"
                )
                
                await voice_message.delete()
                await bot.send_voice(
                    chat_id=message.chat.id,
                    voice=audio_file
                )
                
                # –¢–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                text_prefix = "<i>–¢–µ–∫—Å—Ç:</i> "
                max_length = 4096 - len(text_prefix)
                
                if len(response) > max_length:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                    for i in range(0, len(response), max_length):
                        chunk = response[i:i+max_length]
                        if i == 0:
                            await message.answer(f"{text_prefix}{chunk}", parse_mode="HTML")
                        else:
                            await message.answer(chunk)
                else:
                    await message.answer(f"{text_prefix}{response}", parse_mode="HTML")
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–º
                await voice_message.edit_text(
                    f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å. –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ–∫—Å—Ç–æ–º:\n\n{response}"
                )
        else:
            # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º
            if len(response) > 4096:
                await typing_message.delete()
                for i in range(0, len(response), 4096):
                    await message.answer(response[i:i+4096])
            else:
                await typing_message.edit_text(response)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç {user_id}: {e}")
        await processing_message.edit_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")


@dp.message(F.text)
async def handle_text_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = message.from_user.id
    user_text = message.text
    
    if not user_text:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–æ—á–∫–∞–º–∏ –¥–ª—è –ø–æ–∫–∞–∑–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ "–ø–µ—á–∞—Ç–∏"
    typing_message = await message.answer("...")
    
    try:
        await bot.send_chat_action(chat_id=message.chat.id, action="typing")

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        response = await neuroapi_client.generate_response(user_id, user_text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º
        if neuroapi_client.is_voice_mode_enabled(user_id):
            # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–æ—á–∫–∞–º–∏
            await typing_message.delete()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
            voice_message = await message.answer("üé§ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ–ª–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_voice = neuroapi_client.get_user_voice(user_id)
            
            # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
            audio_data = await neuroapi_client.synthesize_speech(response, user_voice)
            
            if audio_data:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                from aiogram.types import BufferedInputFile
                
                audio_file = BufferedInputFile(
                    file=audio_data,
                    filename="voice_response.ogg"
                )
                
                await voice_message.delete()
                await bot.send_voice(
                    chat_id=message.chat.id,
                    voice=audio_file
                )
                
                # –¢–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                text_prefix = "<i>–¢–µ–∫—Å—Ç:</i> "
                max_length = 4096 - len(text_prefix)
                
                if len(response) > max_length:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                    for i in range(0, len(response), max_length):
                        chunk = response[i:i+max_length]
                        if i == 0:
                            await message.answer(f"{text_prefix}{chunk}", parse_mode="HTML")
                        else:
                            await message.answer(chunk)
                else:
                    await message.answer(f"{text_prefix}{response}", parse_mode="HTML")
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–º
                await voice_message.edit_text(
                    f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å. –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ–∫—Å—Ç–æ–º:\n\n{response}"
                )
        else:
            # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º
            current_model = neuroapi_client._get_user_model(user_id)
            if current_model in ['gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano']:
                parse_mode = "Markdown"
            else:
                parse_mode = None
            
            # –ó–∞–º–µ–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–æ—á–∫–∞–º–∏ –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            if len(response) > 4096:
                # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —É–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–æ—á–∫–∞–º–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ —á–∞—Å—Ç—è–º
                await typing_message.delete()
                for i in range(0, len(response), 4096):
                    await message.answer(response[i:i+4096])
            else:
                await typing_message.edit_text(response)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        try:
            await typing_message.edit_text(
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /clear –¥–ª—è —Å–±—Ä–æ—Å–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
            )
        except:
            await message.answer(
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /clear –¥–ª—è —Å–±—Ä–æ—Å–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
            )

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    
    try:
        # –£–¥–∞–ª—è–µ–º –≤–µ–±—Ö—É–∫–∏ (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ä–∞–Ω–µ–µ)
        await bot.delete_webhook(drop_pending_updates=True)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–ª–∏–Ω–≥
        await dp.start_polling(bot)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞: {e}")
    finally:
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç NeuroAPI
        await neuroapi_client.close()
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é –±–æ—Ç–∞
        await bot.session.close()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
